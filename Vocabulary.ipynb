{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction features....\n",
      "Outlier, Score less than 5\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n",
      "Outlier, no tokens\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction Cell\n",
    "\n",
    "# this finds our json files\n",
    "path_to_json = '../data_folder/json_train/'\n",
    "\n",
    "stop_list = list(STOPWORDS) + [\"sil\", \"uh\", \"um\"]\n",
    "\n",
    "VOCAB = set()\n",
    "score_dict = {}\n",
    "tot = {}\n",
    "voc_dict = {}\n",
    "vocab_list = []\n",
    "\n",
    "new_dict = {}\n",
    "new_dict[\"f_1\"] = []\n",
    "new_dict[\"f_2\"] = []\n",
    "new_dict[\"f_3\"] = []\n",
    "new_dict[\"scores\"] = []\n",
    "new_dict[\"binary_label\"] = []\n",
    "new_dict[\"multiclass_label\"] = []\n",
    "\n",
    "data = []\n",
    "print(\"Extraction features....\")\n",
    "setter = set()\n",
    "inter = set()\n",
    "# we need both the json and an index number so use enumerate()\n",
    "for subdir, dirs, files in os.walk(path_to_json):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            path = os.path.join(subdir, file)\n",
    "            with open(path, 'r') as f:\n",
    "                json_text = json.load(f)\n",
    "            id_ = file\n",
    "            score = json_text[\"score\"]\n",
    "            \n",
    "            if id_ in tot.keys():\n",
    "                continue\n",
    "                \n",
    "            if score < 5:\n",
    "                print(\"Outlier, Score less than 5\")\n",
    "                continue\n",
    "            \n",
    "            if not json_text[\"tokens\"]:\n",
    "                print(\"Outlier, no tokens\")\n",
    "                continue\n",
    "                \n",
    "            text = \"\"\n",
    "            doc_vocab = set()\n",
    "            counter = 0\n",
    "            for tok in json_text[\"tokens\"]:\n",
    "                Text = tok[\"text\"].lower()\n",
    "                if Text not in stop_list:\n",
    "                    text += \" \" + Text\n",
    "                    counter += 1\n",
    "                    doc_vocab.add(Text)\n",
    "                    VOCAB.add(Text)\n",
    "                    vocab_list.append(Text)\n",
    "\n",
    "                \n",
    "            data.append(text)\n",
    "            new_dict[\"scores\"].append(score)\n",
    "            \n",
    "            # new words pr min\n",
    "            f_1 = len(doc_vocab) / json_text[\"elapsed_time\"]\n",
    "            if (f_1 < 0.15):\n",
    "                print('ERRORRRRRR')\n",
    "                print(subdir)\n",
    "                \n",
    "            feature_dict = {}            \n",
    "            feature_dict[\"new_words_pr_min\"] = f_1\n",
    "            \n",
    "            # repeated words pr min\n",
    "            f_2 = len(doc_vocab) / (counter * json_text[\"elapsed_time\"])\n",
    "            feature_dict[\"repeated_words_pr_min\"] = f_2\n",
    "\n",
    "            new_dict[\"f_1\"].append(f_1)\n",
    "            new_dict[\"f_2\"].append(f_2)\n",
    "\n",
    "            feature_dict[\"time\"] = json_text[\"elapsed_time\"]\n",
    "            tot[id_] = feature_dict\n",
    "\n",
    "            voc_dict[id_] = doc_vocab\n",
    "\n",
    "            union = setter.union(doc_vocab - inter)\n",
    "            intersect = setter.intersection(doc_vocab)\n",
    "            setter = union - intersect\n",
    "            inter = intersect\n",
    "\n",
    "            # Labelling process\n",
    "\n",
    "            # Goal: set thresholds to get uniform distribution\n",
    "            if score > 91:\n",
    "                new_dict[\"binary_label\"].append(1)\n",
    "                if score > 95.5:\n",
    "                    new_dict[\"multiclass_label\"].append(3)\n",
    "                else:\n",
    "                    new_dict[\"multiclass_label\"].append(2)\n",
    "            else:\n",
    "                new_dict[\"binary_label\"].append(0)\n",
    "                if (score < 91) & (score > 79):\n",
    "                    new_dict[\"multiclass_label\"].append(1)\n",
    "                else:\n",
    "                    new_dict[\"multiclass_label\"].append(0)\n",
    "\n",
    "# f_3\n",
    "for id_ in tot.keys():\n",
    "    voc = voc_dict[id_]\n",
    "    time = tot[id_][\"time\"]\n",
    "    f_3 = len(voc.intersection(setter)) / (time)\n",
    "    new_dict[\"f_3\"].append(f_3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 3230 data points\n"
     ]
    }
   ],
   "source": [
    "print(\"training on\",len(tot.keys()),\"data points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataframe from dictionary\n"
     ]
    }
   ],
   "source": [
    "print(\"create dataframe from dictionary\")\n",
    "df = pd.DataFrame.from_dict(new_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data\n",
      "Preprocessing done\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF \n",
    "# Feature Extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data)\n",
    "transformer = TfidfTransformer()\n",
    "data = transformer.fit_transform(X).toarray()\n",
    "\n",
    "print(\"Normalizing data\")\n",
    "\n",
    "\n",
    "def normalizer(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        if \"f_\" in feature_name:\n",
    "            max_value = df[feature_name].max()\n",
    "            min_value = df[feature_name].min()\n",
    "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "df = normalizer(df)\n",
    "\n",
    "print(\"Preprocessing done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "F1-F3\n",
      "Preparing binary classification task\n",
      "Accuracy, logistic regression: 0.704\n",
      "F1 score, logistic regression: 0.661\n",
      "Accuracy for RandomForestClassifier: 0.619\n",
      "F1 score, RandomForestClassifier: 0.579\n",
      "Accuracy for Naive Bayes Classifier: 0.669\n",
      "F1 score, Naive Bayes: 0.567\n",
      "Accuracy for Gradient Boosting: 0.695\n",
      "F1 score, Gradient Boosting: 0.579\n",
      "--------------------------------------\n",
      "F1-F3\n",
      "Preparing MULTICLASS classification task\n",
      "Accuracy, logistic regression: 0.379\n",
      "F1 score, logistic regression: 0.483\n",
      "Accuracy for RandomForestClassifier: 0.401\n",
      "F1 score, RandomForestClassifier: 0.408\n",
      "Accuracy for Naive Bayes Classifier: 0.398\n",
      "F1 score, Naive Bayes: 0.472\n",
      "Accuracy for Gradient Boosting: 0.416\n",
      "F1 score, Gradient Boosting: 0.408\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(\"F1-F3\")\n",
    "print(\"Preparing binary classification task\")\n",
    "\n",
    "y = df.iloc[:, -2]\n",
    "X = df.iloc[:, :-3]\n",
    "average = \"binary\"\n",
    "\n",
    "def algo(a_train, a_test, b_train, b_test, pr_cl):\n",
    "\n",
    "    ############Logistic Regression #####################\n",
    "\n",
    "\n",
    "    LR = LogisticRegression(solver='lbfgs', multi_class='ovr').fit(a_train, b_train)\n",
    "    predicted = LR.predict(a_test)\n",
    "\n",
    "\n",
    "    ############Random Forest classifier#####################\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(a_train, b_train)\n",
    "    predictions = rf.predict(a_test)\n",
    "\n",
    "\n",
    "    # ######################## Naive Bayes classifier###############\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(a_train, b_train)\n",
    "    prediction = gnb.predict(a_test)\n",
    "\n",
    "\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "\n",
    "    ########################## Gradient Classifier###################\n",
    "\n",
    "\n",
    "    gb = GradientBoostingClassifier()\n",
    "    gb.fit(a_train, b_train)\n",
    "\n",
    "    if pr_cl == \"binary\":\n",
    "        print(\"Accuracy, logistic regression: {0:.3f}\".format(LR.score(a_test, b_test)))\n",
    "        print(\"F1 score, logistic regression: {0:.3f}\".format(f1_score(predicted, b_test)))\n",
    "\n",
    "        print(\"Accuracy for RandomForestClassifier: {0:.3f}\".format(metrics.accuracy_score(b_test, predictions)))\n",
    "        print(\"F1 score, RandomForestClassifier: {0:.3f}\".format(f1_score(predictions, b_test)))\n",
    "\n",
    "        print(\"Accuracy for Naive Bayes Classifier: {0:.3f}\".format(metrics.accuracy_score(b_test, prediction)))\n",
    "        print(\"F1 score, Naive Bayes: {0:.3f}\".format(f1_score(prediction, b_test)))\n",
    "\n",
    "        print(\"Accuracy for Gradient Boosting: {0:.3f}\".format(gb.score(a_test, b_test)))\n",
    "        print(\"F1 score, Gradient Boosting: {0:.3f}\".format(f1_score(predictions, b_test)))\n",
    "\n",
    "    else:\n",
    "        print(\"Accuracy, logistic regression: {0:.3f}\".format(LR.score(a_test, b_test)))\n",
    "        print(\"F1 score, logistic regression: {0:.3f}\".format(f1_score(predicted, b_test, average='weighted')))\n",
    "\n",
    "        print(\"Accuracy for RandomForestClassifier: {0:.3f}\".format(metrics.accuracy_score(b_test, predictions)))\n",
    "        print(\"F1 score, RandomForestClassifier: {0:.3f}\".format(f1_score(predictions, b_test, average='weighted')))\n",
    "\n",
    "        print(\"Accuracy for Naive Bayes Classifier: {0:.3f}\".format(metrics.accuracy_score(b_test, prediction)))\n",
    "        print(\"F1 score, Naive Bayes: {0:.3f}\".format(f1_score(prediction, b_test, average='weighted')))\n",
    "\n",
    "        print(\"Accuracy for Gradient Boosting: {0:.3f}\".format(gb.score(a_test, b_test)))\n",
    "        print(\"F1 score, Gradient Boosting: {0:.3f}\".format(f1_score(predictions, b_test, average='weighted')))\n",
    "\n",
    "\n",
    "\n",
    "a_train, a_test, b_train, b_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "algo(a_train, a_test, b_train, b_test, average)\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(\"F1-F3\")\n",
    "print(\"Preparing MULTICLASS classification task\")\n",
    "\n",
    "y = df.iloc[:, -1]\n",
    "average = \"weighted\"\n",
    "a_train, a_test, b_train, b_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "algo(a_train, a_test, b_train, b_test, average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\n",
      "TF-IDF\n",
      "Preparing BINARY classification task\n",
      "Accuracy, logistic regression: 0.684\n",
      "F1 score, logistic regression: 0.715\n",
      "Accuracy for RandomForestClassifier: 0.641\n",
      "F1 score, RandomForestClassifier: 0.590\n",
      "Accuracy for Naive Bayes Classifier: 0.596\n",
      "F1 score, Naive Bayes: 0.590\n",
      "Accuracy for Gradient Boosting: 0.676\n",
      "F1 score, Gradient Boosting: 0.590\n",
      "--------------------------------------\n",
      "Preparing MULTICLASS classification task\n",
      "Accuracy, logistic regression: 0.443\n",
      "F1 score, logistic regression: 0.442\n",
      "Accuracy for RandomForestClassifier: 0.402\n",
      "F1 score, RandomForestClassifier: 0.402\n",
      "Accuracy for Naive Bayes Classifier: 0.356\n",
      "F1 score, Naive Bayes: 0.356\n",
      "Accuracy for Gradient Boosting: 0.443\n",
      "F1 score, Gradient Boosting: 0.402\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ONLY TF-IDF AS PREDICTIVE FEATURE\n",
    "print(\"HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\")\n",
    "print(\"TF-IDF\")\n",
    "print(\"Preparing BINARY classification task\")\n",
    "y = df.iloc[:, -2]\n",
    "average = \"binary\"\n",
    "a_train, a_test, b_train, b_test = train_test_split(data, y, test_size=0.20, random_state=42)\n",
    "algo(a_train, a_test, b_train, b_test, average)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Preparing MULTICLASS classification task\")\n",
    "\n",
    "y = df.iloc[:, -1]\n",
    "average = \"weighted\"\n",
    "a_train, a_test, b_train, b_test = train_test_split(data, y, test_size=0.20, random_state=42)\n",
    "algo(a_train, a_test, b_train, b_test, average)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run SVD on Data frame to deal with sparsity\n",
      "Preparing BINARY classification task, TF-IDF with SVD\n",
      "Accuracy, logistic regression: 0.534\n",
      "F1 score, logistic regression: 0.642\n",
      "Accuracy for RandomForestClassifier: 0.599\n",
      "F1 score, RandomForestClassifier: 0.551\n",
      "Accuracy for Naive Bayes Classifier: 0.550\n",
      "F1 score, Naive Bayes: 0.088\n",
      "Accuracy for Gradient Boosting: 0.579\n",
      "F1 score, Gradient Boosting: 0.551\n",
      "--------------------------------------\n",
      "Preparing MULTICLASS classification task, TF-IDF with SVD\n",
      "Accuracy, logistic regression: 0.344\n",
      "F1 score, logistic regression: 0.444\n",
      "Accuracy for RandomForestClassifier: 0.365\n",
      "F1 score, RandomForestClassifier: 0.367\n",
      "Accuracy for Naive Bayes Classifier: 0.293\n",
      "F1 score, Naive Bayes: 0.402\n",
      "Accuracy for Gradient Boosting: 0.398\n",
      "F1 score, Gradient Boosting: 0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Run SVD on Data frame to deal with sparsity\")\n",
    "\n",
    "\n",
    "# Training -------------------------------------\n",
    "\n",
    "raw_data = normalize(data, axis = 0)\n",
    "\n",
    "svd = TruncatedSVD(n_components=5)\n",
    "svd.fit(raw_data)\n",
    "new_data = svd.transform(raw_data)\n",
    "\n",
    "print(\"Preparing BINARY classification task, TF-IDF with SVD\")\n",
    "# With SVD\n",
    "y = df.iloc[:, -2]\n",
    "average = \"binary\"\n",
    "a_train, a_test, b_train, b_test = train_test_split(new_data, y, test_size=0.20, random_state=42)\n",
    "algo(a_train, a_test, b_train, b_test, average)\n",
    "\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Preparing MULTICLASS classification task, TF-IDF with SVD\")\n",
    "\n",
    "y = df.iloc[:, -1]\n",
    "average = \"weighted\"\n",
    "a_train, a_test, b_train, b_test = train_test_split(new_data, y, test_size=0.20, random_state=42)\n",
    "algo(a_train, a_test, b_train, b_test, average)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Preparing regression task\n",
      "F1-F3\n",
      "Root Mean square error\n",
      "13.687577918345099\n",
      "TF-IDF\n",
      "Root Mean square error\n",
      "11.911533775624772\n",
      "TF-IDF, SVD\n",
      "Root Mean square error\n",
      "13.03805680874539\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "################### Regression########################\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Preparing regression task\")\n",
    "\n",
    "def regressor(a_train, a_test, b_train, b_test):\n",
    "    LinR = LinearRegression().fit(a_train, b_train)\n",
    "    predicted = LinR.predict(a_test)\n",
    "    rmse = sqrt(mean_squared_error(predicted, b_test))\n",
    "    print(\"Root Mean square error\")\n",
    "    print(rmse)\n",
    "\n",
    "\n",
    "y = df.iloc[:, -3]\n",
    "\n",
    "\n",
    "print(\"F1-F3\")\n",
    "a_train, a_test, b_train, b_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "regressor(a_train, a_test, b_train, b_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"TF-IDF\")\n",
    "a_train, a_test, b_train, b_test = train_test_split(data, y, test_size=0.20, random_state=42)\n",
    "regressor(a_train, a_test, b_train, b_test)\n",
    "\n",
    "\n",
    "print(\"TF-IDF, SVD\")\n",
    "a_train, a_test, b_train, b_test = train_test_split(new_data, y, test_size=0.20, random_state=42)\n",
    "regressor(a_train, a_test, b_train, b_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
